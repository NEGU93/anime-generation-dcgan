{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN\n",
    "# Deep Convolutional Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\n",
    "##### Alec Radford, Luke Metz, Soumith Chintala\n",
    "\n",
    "In recent years, supervised learning with **convolutional networks (CNNs)** has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the **gap between the success of CNNs for supervised learning and unsupervised learning.** We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Network\n",
    "\n",
    "Las gan se basan en un punto de vista de teoría de juegos. Al contrario de una red neuronal convencional. En las gan se utilizan dos redes neuronales que reciben el nombre de **Generador** y **Discriminador**. Dichas redes están en constante competencia entre ellas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generative Adversarial Networks\n",
    "##### Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio\n",
    "\n",
    "We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![GAN Diagram](img/1_XKanAdkjQbg1eDDMF2-4ow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta distribución, la red generadora intenta generar imágenes que logren engañar al discriminador haciendole creer que las imágenes son originales. El discriminador por su parte trata de no ser engañado e intenta distinguir si las imágenes fueron originales o no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Function\n",
    "\n",
    "El discriminador trata de maximizar la función (gradient ascent) mientras que el discriminador trata de minimizarla (gradient descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-11T22:42:09.297309Z",
     "start_time": "2018-08-11T22:42:09.267330Z"
    }
   },
   "source": [
    "![Objective Function](img/1_FbQLpEVQKsMSK-c7_5KcWw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, al aplicar esta ecuación, el generador no funciona tan bien. Esto sucede porque cuando una imagen es generada es probable que lo clasifique como falso. El gradiende tiende a ser bastante plano y dificulta que el modelo aprenda correctamente. Por dicho motivo se cambia la función del generador por la siguiente:\n",
    "\n",
    "![Generator Objective Function](img/1_ZHKnky7Pzi5OvPlUIZhDjg.png)\n",
    "\n",
    "Es decir, que en lugar de minimizar la probabilidad de que el discriminador tenga razón, maximiza el *likelyhood* de que el discriminador se equivoque."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generador\n",
    "\n",
    "![Generator](img/gernerator.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La entrada del generador es una entrada aleatoria denominada *latent sample*. El generador toma esa entrada y la convierte en la imagen generada.\n",
    "\n",
    "Resulta evidente que sin entrenamiento, la salida de la red será ruido sin significado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminador \n",
    "\n",
    "El discriminador recibe una imágen y dice si la misma fue real (1) o no (0).\n",
    "\n",
    "![Generator](img/disc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-11T23:36:09.964480Z",
     "start_time": "2018-08-11T23:36:09.955486Z"
    }
   },
   "source": [
    "### Entrenamiento\n",
    "    1. Poner el discriminador en modo de entrenamiento\n",
    "    2. Entrenar el discriminador tanto con imágenes generadas como reales\n",
    "    3. Poner el discriminador en modo de no entrenamiento\n",
    "    4. Entrenar el generador como parte de la GAN\n",
    "    5. Repetir paso 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A tener en cuenta\n",
    "\n",
    "Si el discriminador entrena mucho más rápido que el generador, el generador nunca logra engañar al discriminador. Lo mismo aplica para el otro caso en donde el discriminador termina no pudiendo clasificar apropiadamente. Se debe tener cuidado para lograr que ambos logren entrenarse a un ritmo similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks\n",
    "\n",
    "CNNs son especialmente útiles para clasificación y reconocimiento de imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN poseen a grandes rasgos dos componentes principales:\n",
    "    1. Las capas ocultas (feature extraction)\n",
    "    2. Clasificación\n",
    "    \n",
    "![Generator](img/1_NQQiyYqJJj4PSYAeWvxutg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "\n",
    "En este componente se realizan operaciones de **convolucion** y **pooling** en las cuales los patrones son detectados.\n",
    "\n",
    "Si se buscara reconocer una zebra por ejemplo, esta etapa reconocería las rayas, dos oídos y cuatro patas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolución\n",
    "\n",
    "En la convolución se dice que se convoluciona la imagen de entrada con un **kernel** o **filtro** para generar un **feature map**. Para realizar la convolución se mueve el filtro sobre la imagen de entrada multiplicando y sumando el resultado en el *feature map*. \n",
    "\n",
    "En la siguiente imágen peude observarse claramente cómo se realiza dicha operación.\n",
    "![conv](img/1_VVvdh-BUKFh2pwDD0kPeRA@2x.gif)\n",
    "\n",
    "En la práctica se realizan numerosas convoluciones sobre la entrada usando diferentes filtros. Esto genera numerosos *feature maps* los cuales se los junta para obtener la salida final de la capa de convolución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función de activación\n",
    "\n",
    "Como en cualquier otra red neuronal, se usa una **función de activación** para que la salida sea no lineal. Por ejemplo la función ReLU (Rectified Linear Units - https://github.com/Kulbear/deep-learning-nano-foundation/wiki/ReLU-and-Softmax-Activation-Functions)\n",
    "\n",
    "$$ f(x) = max(x, 0) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stride\n",
    "\n",
    "Stride se le llama al *paso* (cantidad de pixels) que el filtro debe moverse a cada iteración. Usualmente es 1. Aumentando dicho número puede reducirse el overlap.\n",
    "\n",
    "![stride](img/0_iqNdZWyNeCr5tCkc_.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding\n",
    "\n",
    "El tamaño del *feature map* es SIEMPRE menor que el input. Es por eso que se debe usar **padding**.\n",
    "\n",
    "Una capa de pixels nulos (valor cero) se agrega al input, rodeando al mismo de ceros y aumentando de esa forma su tamaño. De esta forma se logra que no se reduzca el *feature map*. El ejemplo de stride superior incluye un padding representado por los cuadrados de linea punteada.\n",
    "\n",
    "El padding además, mejora la performance y se asegura que el tamaño del kernel y del stride sean coherentes con la entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pooling\n",
    "\n",
    "Luego de una capa de convolución, es común agregar una capa de **pooling**. Su función es reducir continuamente las dimensiones reduciendo la complejidad de la red.\n",
    "\n",
    "Lo mismo decrementa el tiempo de entrenamiento y reduce el overfitting.\n",
    "\n",
    "##### Max Pooling\n",
    "\n",
    "El modo más común de pooling se llama **max pooling** el cual toma el máximo valor de cada ventana. En la siguiente figura se muestra un ejemplo de max pooling:\n",
    "\n",
    "![stride](img/1_vbfPq-HvBCkAcZhiSTZybg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resumen\n",
    "\n",
    "Al usar una CNN hay 4 hiperparámetros importantes entre los cuales decidir:\n",
    "\n",
    "1. Kernel size\n",
    "2. Filter count (cuantos filtros usar)\n",
    "3. Stride\n",
    "4. Padding\n",
    "\n",
    "Visualización de una capa convolucional:\n",
    "\n",
    "![stride](img/1__34EtrgYk6cQxlJ2br51HQ.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "Ocurre luego de las capas de convolución y pooling.\n",
    "\n",
    "Clasifica como una red convencional sobre los patrones obtenidos.\n",
    "\n",
    "La parte de clasificación simplemente consiste en una red fully connected convirtiendo la matriz 3D (o 2D si es grayscale) en un vector 1D.\n",
    "\n",
    "La red se entrena igual que cualquier otra red, usando backpropagation / gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN\n",
    "\n",
    "![Generator](img/1_39Nnni_nhPDaLu9AnTLoWw.png)\n",
    "https://medium.com/@awjuliani/generative-adversarial-networks-explained-with-a-classic-spongebob-squarepants-episode-54deab2fce39"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Train a GAN? Tips and tricks to make GANs work\n",
    "https://github.com/soumith/ganhacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "415px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
